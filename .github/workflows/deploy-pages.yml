name: Build and Deploy (Stats Dashboard)

on:
  workflow_dispatch:
  schedule:
    - cron: "0 6 * * *"

permissions:
  contents: read
  actions: write
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  build:
    runs-on: ubuntu-latest
    env:
      BASE_URL: /hoops-insight/
      BP_OWNER: "Alex-2911"
      BP_REPO: "Basketball_prediction"
      BP_BRANCH: "2026"
      BP_WORKFLOW_FILE: "1_get_data_previous_game_day_2026.yml"

    steps:
      - name: Checkout hoops-insight repo
        uses: actions/checkout@v4

      - name: Checkout Basketball_prediction repo (branch 2026)
        uses: actions/checkout@v4
        with:
          repository: Alex-2911/Basketball_prediction
          ref: 2026
          path: Basketball_prediction
          fetch-depth: 1

      - name: Install system tools (jq)
        shell: bash
        run: |
          set -euo pipefail
          sudo apt-get update
          sudo apt-get install -y jq

      # IMPORTANT: github.token won't trigger workflows in ANOTHER repo.
      # You need a PAT in secrets.BP_TOKEN with permissions on Basketball_prediction.
      - name: Trigger Basketball_prediction pipeline (Scraper)
        shell: bash
        env:
          BP_TOKEN: ${{ secrets.BP_TOKEN }}
        run: |
          set -euo pipefail
          if [[ -z "${BP_TOKEN:-}" ]]; then
            echo "ERROR: secrets.BP_TOKEN is required to trigger cross-repo workflow."
            exit 1
          fi

          echo "Triggering workflow '$BP_WORKFLOW_FILE' in $BP_OWNER/$BP_REPO on branch=$BP_BRANCH"
          WF_ENC="${BP_WORKFLOW_FILE// /%20}"

          curl -fLsS -X POST \
            -H "Authorization: Bearer $BP_TOKEN" \
            -H "Accept: application/vnd.github+json" \
            -d "{\"ref\":\"$BP_BRANCH\"}" \
            "https://api.github.com/repos/$BP_OWNER/$BP_REPO/actions/workflows/$WF_ENC/dispatches"

          echo "✔ Triggered."

      - name: Wait for scraper workflow run to succeed (cross-repo)
        shell: bash
        env:
          BP_TOKEN: ${{ secrets.BP_TOKEN }}
        run: |
          set -euo pipefail
          if [[ -z "${BP_TOKEN:-}" ]]; then
            echo "ERROR: secrets.BP_TOKEN is required to query cross-repo workflow status."
            exit 1
          fi

          echo "Waiting for workflow '$BP_WORKFLOW_FILE' on branch=$BP_BRANCH to complete successfully..."
          WF_ENC="${BP_WORKFLOW_FILE// /%20}"

          # Wait up to ~10 minutes (60 * 10s)
          for i in {1..60}; do
            RUN=$(curl -fsS \
              -H "Authorization: Bearer $BP_TOKEN" \
              -H "Accept: application/vnd.github+json" \
              "https://api.github.com/repos/$BP_OWNER/$BP_REPO/actions/workflows/$WF_ENC/runs?branch=$BP_BRANCH&per_page=1")

            ID=$(echo "$RUN" | jq -r '.workflow_runs[0].id // empty')
            STATUS=$(echo "$RUN" | jq -r '.workflow_runs[0].status // empty')
            CONCLUSION=$(echo "$RUN" | jq -r '.workflow_runs[0].conclusion // empty')

            echo "Attempt $i → RunID=${ID:-?} | status=${STATUS:-?} | conclusion=${CONCLUSION:-?}"

            if [[ "$STATUS" == "completed" && "$CONCLUSION" == "success" ]]; then
              echo "✔ Latest scraper run succeeded!"
              exit 0
            fi

            echo "Not successful yet — waiting 10s..."
            sleep 10
          done

          echo "✖ Workflow did not succeed in time."
          exit 1

      - name: Refresh Basketball_prediction checkout to latest commit (after scraper)
        shell: bash
        run: |
          set -euo pipefail
          git -C Basketball_prediction fetch origin "$BP_BRANCH" --depth=1
          git -C Basketball_prediction checkout "$BP_BRANCH"
          git -C Basketball_prediction reset --hard "origin/$BP_BRANCH"
          echo "✔ Basketball_prediction refreshed to latest origin/$BP_BRANCH"
          git -C Basketball_prediction log -1 --oneline

      - name: Setup Python with pip cache
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: Basketball_prediction/requirements.txt

      - name: Install Python deps (from Basketball_prediction)
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install -r Basketball_prediction/requirements.txt

      - name: Verify required source files exist (tolerate both output layouts)
        shell: bash
        run: |
          set -euo pipefail

          ROOT_OUT="$GITHUB_WORKSPACE/Basketball_prediction/2026/output/LightGBM"
          ROOT_FLAT="$GITHUB_WORKSPACE/Basketball_prediction/2026/LightGBM"

          echo "[debug] ROOT_OUT=$ROOT_OUT (exists=$(test -d "$ROOT_OUT" && echo yes || echo no))"
          echo "[debug] ROOT_FLAT=$ROOT_FLAT (exists=$(test -d "$ROOT_FLAT" && echo yes || echo no))"

          # combined iso can be in output/LightGBM/Kelly/
          COMBINED=$(
            (find "$ROOT_OUT" -maxdepth 2 -name "combined_nba_predictions_iso*.csv" -type f -printf "%T@ %p\n" 2>/dev/null || true; \
             find "$ROOT_FLAT" -maxdepth 2 -name "combined_nba_predictions_iso*.csv" -type f -printf "%T@ %p\n" 2>/dev/null || true) \
            | sort -nr | head -n1 | cut -d' ' -f2-
          )

          # local matched can be in output/LightGBM/ OR flat LightGBM/
          LOCAL_MATCHED=$(
            (find "$ROOT_OUT" -maxdepth 1 -name "local_matched_games_*.csv" -type f -printf "%T@ %p\n" 2>/dev/null || true; \
             find "$ROOT_FLAT" -maxdepth 1 -name "local_matched_games_*.csv" -type f -printf "%T@ %p\n" 2>/dev/null || true) \
            | sort -nr | head -n1 | cut -d' ' -f2-
          )

          # metrics snapshot can be in output/LightGBM/ OR flat LightGBM/
          METRICS=$(
            (find "$ROOT_OUT" -maxdepth 2 -name "metrics_snapshot*.json" -type f -printf "%T@ %p\n" 2>/dev/null || true; \
             find "$ROOT_FLAT" -maxdepth 2 -name "metrics_snapshot*.json" -type f -printf "%T@ %p\n" 2>/dev/null || true) \
            | sort -nr | head -n1 | cut -d' ' -f2-
          )

          # optional
          BET_LOG_FLAT=$(
            (find "$ROOT_OUT" -maxdepth 2 -name "bet_log_flat_live*.csv" -type f -printf "%T@ %p\n" 2>/dev/null || true; \
             find "$ROOT_FLAT" -maxdepth 2 -name "bet_log_flat_live*.csv" -type f -printf "%T@ %p\n" 2>/dev/null || true) \
            | sort -nr | head -n1 | cut -d' ' -f2-
          )

          STRATEGY_PARAMS=$(
            (find "$ROOT_OUT" -maxdepth 2 -name "strategy_params*.json" -o -name "strategy_params*.txt" -type f -printf "%T@ %p\n" 2>/dev/null || true; \
             find "$ROOT_FLAT" -maxdepth 2 -name "strategy_params*.json" -o -name "strategy_params*.txt" -type f -printf "%T@ %p\n" 2>/dev/null || true) \
            | sort -nr | head -n1 | cut -d' ' -f2-
          )

          echo "✔ Found combined: ${COMBINED:-missing}"
          echo "✔ Found local_matched_games: ${LOCAL_MATCHED:-missing}"
          echo "✔ Found metrics_snapshot: ${METRICS:-missing}"
          echo "✔ Found bet_log_flat: ${BET_LOG_FLAT:-missing}"
          echo "✔ Found strategy_params: ${STRATEGY_PARAMS:-missing}"

          if [[ -z "${COMBINED:-}" || -z "${LOCAL_MATCHED:-}" || -z "${METRICS:-}" ]]; then
            echo "ERROR: Missing required source files (combined/local_matched/metrics)." >&2
            exit 1
          fi

      - name: Copy dashboard sources into public/data (pick newest across both layouts)
        shell: bash
        run: |
          set -euo pipefail

          ROOT_OUT="$GITHUB_WORKSPACE/Basketball_prediction/2026/output/LightGBM"
          ROOT_FLAT="$GITHUB_WORKSPACE/Basketball_prediction/2026/LightGBM"
          OUT="$GITHUB_WORKSPACE/public/data"
          mkdir -p "$OUT"

          pick_latest () {
            # usage: pick_latest "<find args...>"
            # prints chosen file path or empty
            local candidates
            candidates=$(eval "$1" 2>/dev/null || true)
            if [[ -z "$candidates" ]]; then
              echo ""
              return 0
            fi
            echo "$candidates" | sort -nr | head -n1 | cut -d' ' -f2-
          }

          COMBINED=$(pick_latest "(find \"$ROOT_OUT\" -maxdepth 2 -name \"combined_nba_predictions_iso*.csv\" -type f -printf \"%T@ %p\n\"; find \"$ROOT_FLAT\" -maxdepth 2 -name \"combined_nba_predictions_iso*.csv\" -type f -printf \"%T@ %p\n\")")
          LOCAL_MATCHED=$(pick_latest "(find \"$ROOT_OUT\" -maxdepth 1 -name \"local_matched_games_*.csv\" -type f -printf \"%T@ %p\n\"; find \"$ROOT_FLAT\" -maxdepth 1 -name \"local_matched_games_*.csv\" -type f -printf \"%T@ %p\n\")")
          METRICS=$(pick_latest "(find \"$ROOT_OUT\" -maxdepth 2 -name \"metrics_snapshot*.json\" -type f -printf \"%T@ %p\n\"; find \"$ROOT_FLAT\" -maxdepth 2 -name \"metrics_snapshot*.json\" -type f -printf \"%T@ %p\n\")")
          BET_LOG_FLAT=$(pick_latest "(find \"$ROOT_OUT\" -maxdepth 2 -name \"bet_log_flat_live*.csv\" -type f -printf \"%T@ %p\n\"; find \"$ROOT_FLAT\" -maxdepth 2 -name \"bet_log_flat_live*.csv\" -type f -printf \"%T@ %p\n\")")
          STRATEGY_PARAMS=$(pick_latest "(find \"$ROOT_OUT\" -maxdepth 2 \\( -name \"strategy_params*.json\" -o -name \"strategy_params*.txt\" \\) -type f -printf \"%T@ %p\n\"; find \"$ROOT_FLAT\" -maxdepth 2 \\( -name \"strategy_params*.json\" -o -name \"strategy_params*.txt\" \\) -type f -printf \"%T@ %p\n\")")

          cp "$METRICS" "$OUT/metrics_snapshot.json"
          cp "$COMBINED" "$OUT/combined_latest.csv"
          cp "$LOCAL_MATCHED" "$OUT/local_matched_games_latest.csv"

          if [[ -n "${BET_LOG_FLAT:-}" && -f "$BET_LOG_FLAT" ]]; then
            cp "$BET_LOG_FLAT" "$OUT/bet_log_flat_live.csv"
          fi

          if [[ -n "${STRATEGY_PARAMS:-}" && -f "$STRATEGY_PARAMS" ]]; then
            # normalize to json if needed? keep original name for now
            if [[ "$STRATEGY_PARAMS" == *.json ]]; then
              cp "$STRATEGY_PARAMS" "$OUT/strategy_params.json"
            else
              cp "$STRATEGY_PARAMS" "$OUT/strategy_params.txt"
            fi
          fi

          echo "✔ Copied dashboard artifacts into $OUT"
          ls -la "$OUT"


      - name: Generate dashboard data (from public/data sources)
        shell: bash
        run: |
          set -euo pipefail
          python scripts/generate_dashboard_data.py --data-dir "$GITHUB_WORKSPACE/public/data"

      - name: Validate dashboard payload parity
        shell: bash
        run: |
          set -euo pipefail
          test -f public/data/dashboard_payload.json
          python scripts/validate_dashboard_payload.py --path public/data/dashboard_payload.json

      - name: Validate dashboard state parity
        shell: bash
        run: |
          set -euo pipefail
          test -f public/data/dashboard_state.json
          node scripts/validate_dashboard_state.mjs public/data

      # IMPORTANT for V1:
      # Pages should load deterministic snapshot paths => copy generated JSONs into public/data/published/
      - name: Publish snapshot into public/data/published (for PROD fetch)
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p public/data/published
          cp public/data/dashboard_payload.json public/data/published/dashboard_payload.json
          cp public/data/dashboard_state.json public/data/published/dashboard_state.json
          cp public/data/summary.json public/data/published/summary.json
          cp public/data/tables.json public/data/published/tables.json
          cp public/data/last_run.json public/data/published/last_run.json
          if [[ -f public/data/strategy_params.json ]]; then
            cp public/data/strategy_params.json public/data/published/strategy_params.json
          fi
          echo "✔ Snapshot prepared in public/data/published/"
          ls -la public/data/published

      - name: Setup Node 20
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "npm"

      - name: Install Node deps & build
        shell: bash
        run: |
          set -euo pipefail
          npm ci
          npm run build -- --base="$BASE_URL"
          cp dist/index.html dist/404.html
          echo "✔ Dashboard build finished."

      - name: Verify build output and base path
        shell: bash
        run: |
          set -euo pipefail
          [[ -d dist/assets ]] || (echo "Missing dist/assets output." && exit 1)
          grep -n "/hoops-insight/" dist/index.html >/dev/null
          echo "✔ Build output verified for GitHub Pages base path."

      - name: Upload dashboard to Pages
        uses: actions/upload-pages-artifact@v3
        with:
          path: dist

  deploy:
    runs-on: ubuntu-latest
    needs: build
    steps:
      - name: Deploy dashboard to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
