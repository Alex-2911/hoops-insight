name: Build and Deploy (Stats Dashboard)

on:
  workflow_dispatch:
  schedule:
    - cron: "0 6 * * *"

permissions:
  contents: read
  actions: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  build:
    runs-on: ubuntu-latest
    env:
      BASE_URL: /hoops-insight/
      SOURCE_ROOT: ${{ github.workspace }}/Basketball_prediction/2026
      N_WINDOW: 200

      # --- Basketball_prediction wiring ---
      BP_OWNER: Alex-2911
      BP_REPO: Basketball_prediction
      BP_BRANCH: "2026"

      # IMPORTANT:
      # Set this to the actual workflow file name in Alex-2911/Basketball_prediction
      # that produces the artifacts (metrics-snapshot + betting_shortlist_and_logs).
      # Example: update_betting_stats_and_shortlist.yml
      BP_WORKFLOW_FILE: "1_get_data_previous_game_day_2026.yml"

      BP_ARTIFACT_METRICS: "metrics-snapshot"
      BP_ARTIFACT_LOGS: "betting_shortlist_and_logs"

    steps:
      - name: Checkout hoops-insight
        uses: actions/checkout@v4

      # We still checkout Basketball_prediction repo because your generator expects the folder structure,
      # but we won't run the heavy pipeline here; we just place artifacts into its output directory.
      - name: Checkout Basketball_prediction (code + folder structure)
        uses: actions/checkout@v4
        with:
          repository: Alex-2911/Basketball_prediction
          ref: 2026
          path: Basketball_prediction
          fetch-depth: 1

      - name: Trigger Basketball_prediction pipeline first
        env:
          BP_OWNER: "Alex-2911"
          BP_REPO: "Basketball_prediction"
          BP_BRANCH: "2026"
          BP_WORKFLOW_FILE: "1_get_data_previous_game_day 2026.yml"
          BP_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail
          echo "Triggering workflow '$BP_WORKFLOW_FILE' in $BP_OWNER/$BP_REPO on branch $BP_BRANCH"
      
          # URL-encode spaces im Workflow-File-Name
          WF_ENC="${BP_WORKFLOW_FILE// /%20}"
      
          curl -fLsS -X POST \
            -H "Authorization: Bearer $BP_TOKEN" \
            -H "Accept: application/vnd.github+json" \
            -d "{\"ref\":\"$BP_BRANCH\"}" \
            "https://api.github.com/repos/$BP_OWNER/$BP_REPO/actions/workflows/$WF_ENC/dispatches"
      
          echo "Triggered."


      - name: Wait for latest Basketball_prediction run to complete successfully (branch 2026)
        shell: bash
        env:
          BP_TOKEN: ${{ secrets.BP_TOKEN }}
        run: |
          set -euo pipefail

          python - <<'PY'
          import os, time, json, urllib.request

          owner = os.environ["BP_OWNER"]
          repo = os.environ["BP_REPO"]
          branch = os.environ["BP_BRANCH"]
          token = os.environ["BP_TOKEN"]

          def gh_get(url: str):
            req = urllib.request.Request(
              url,
              headers={
                "Authorization": f"Bearer {token}",
                "Accept": "application/vnd.github+json",
                "User-Agent": "hoops-insight-ci",
              },
            )
            with urllib.request.urlopen(req) as r:
              return json.loads(r.read().decode("utf-8"))

          # Poll latest run on branch until completed.
          # (Hard cap to avoid infinite loops.)
          deadline = time.time() + 15 * 60  # 15 minutes

          last_seen = None
          while True:
            runs = gh_get(
              f"https://api.github.com/repos/{owner}/{repo}/actions/runs"
              f"?branch={branch}&per_page=5"
            )
            wr = runs.get("workflow_runs", [])
            if not wr:
              print("No runs found yet; sleeping...")
              time.sleep(10)
              continue

            run = wr[0]
            run_id = run["id"]
            status = run["status"]
            conclusion = run.get("conclusion")

            if run_id != last_seen:
              print(f"Latest run id={run_id} name={run.get('name')} status={status} conclusion={conclusion}")
              last_seen = run_id
            else:
              print(f"Still waitingâ€¦ id={run_id} status={status} conclusion={conclusion}")

            if status == "completed":
              if conclusion == "success":
                # Emit run id to a file so bash can read it
                with open("/tmp/bp_run_id.txt", "w", encoding="utf-8") as f:
                  f.write(str(run_id))
                print(f"SUCCESS run_id={run_id}")
                break
              raise SystemExit(f"Basketball_prediction run completed but not successful: {conclusion} (run_id={run_id})")

            if time.time() > deadline:
              raise SystemExit("Timed out waiting for Basketball_prediction run to complete")

            time.sleep(15)
          PY

          echo "BP_RUN_ID=$(cat /tmp/bp_run_id.txt)" >> "$GITHUB_ENV"

      - name: Download Basketball_prediction artifacts into output directory
        shell: bash
        env:
          BP_TOKEN: ${{ secrets.BP_TOKEN }}
        run: |
          set -euo pipefail

          echo "Downloading artifacts from run: $BP_RUN_ID"
          TARGET_DIR="Basketball_prediction/2026/output/LightGBM"
          mkdir -p "$TARGET_DIR"

          python - <<'PY'
          import os, json, urllib.request, subprocess, pathlib

          owner = os.environ["BP_OWNER"]
          repo  = os.environ["BP_REPO"]
          run_id = os.environ["BP_RUN_ID"]
          token = os.environ["BP_TOKEN"]

          want = {os.environ["BP_ARTIFACT_METRICS"], os.environ["BP_ARTIFACT_LOGS"]}
          target_dir = pathlib.Path("Basketball_prediction/2026/output/LightGBM")
          target_dir.mkdir(parents=True, exist_ok=True)

          def gh_get(url: str):
            req = urllib.request.Request(
              url,
              headers={
                "Authorization": f"Bearer {token}",
                "Accept": "application/vnd.github+json",
                "User-Agent": "hoops-insight-ci",
              },
            )
            with urllib.request.urlopen(req) as r:
              return json.loads(r.read().decode("utf-8"))

          arts = gh_get(f"https://api.github.com/repos/{owner}/{repo}/actions/runs/{run_id}/artifacts")
          found = {}
          for a in arts.get("artifacts", []):
            name = a.get("name")
            if name in want:
              found[name] = a.get("archive_download_url")

          missing = want - set(found.keys())
          if missing:
            raise SystemExit(f"Missing artifacts in run {run_id}: {sorted(missing)}")

          for name, url in found.items():
            zip_path = f"/tmp/{name}.zip"
            subprocess.check_call([
              "curl", "-fLsS", "-L",
              "-H", f"Authorization: Bearer {token}",
              "-H", "Accept: application/vnd.github+json",
              url, "-o", zip_path
            ])
            subprocess.check_call(["unzip", "-o", zip_path, "-d", str(target_dir)])

          # sanity checks (hard requirements)
          required = [
            target_dir / "metrics_snapshot.json",
            target_dir / "strategy_params.txt",
          ]
          for p in required:
            if not p.exists():
              raise SystemExit(f"Expected file missing after unzip: {p}")

          print("Artifacts downloaded & verified OK.")
          PY

      - name: Verify Basketball_prediction outputs exist
        shell: bash
        run: |
          set -euo pipefail
          LIGHTGBM_DIR="$GITHUB_WORKSPACE/Basketball_prediction/2026/output/LightGBM"
          echo "LIGHTGBM_DIR=$LIGHTGBM_DIR"
          ls -la "$LIGHTGBM_DIR" | head -n 80

          test -f "$LIGHTGBM_DIR/metrics_snapshot.json" || (echo "Missing metrics_snapshot.json" && exit 1)
          test -f "$LIGHTGBM_DIR/strategy_params.txt" || (echo "Missing strategy_params.txt" && exit 1)
          if ! ls "$LIGHTGBM_DIR"/local_matched_games_*.csv >/dev/null 2>&1; then
            echo "WARN: No local_matched_games_*.csv found (no trades)."
          fi

      - name: Install Python deps (hoops-insight)
        run: |
          python -m pip install --upgrade pip
          python -m pip install -r requirements.txt

      - name: Build dashboard data
        env:
          SOURCE_ROOT: ${{ github.workspace }}/Basketball_prediction/2026
          N_WINDOW: 200
          BASE_URL: /hoops-insight/
        run: python scripts/generate_dashboard_data.py

      - name: Verify dashboard artifacts
        run: |
          set -euo pipefail
          test -f public/data/summary.json
          test -f public/data/tables.json
          test -f public/data/last_run.json

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "npm"

      - name: Install Node deps
        run: npm ci

      - name: Build
        run: npm run build

      - name: Sanity check dist index
        run: test -f dist/index.html

      - name: Configure Pages
        uses: actions/configure-pages@v5

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: dist

      - name: Debug on failure (find LightGBM files)
        if: failure()
        shell: bash
        run: |
          set -euo pipefail
          echo "=== find LightGBM files ==="
          find Basketball_prediction/2026/output/LightGBM -maxdepth 2 -type f | sort | tail -n 200

  deploy:
    runs-on: ubuntu-latest
    needs: build
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
